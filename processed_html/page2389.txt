Satellite image-based maps: Scientific inference or pretty pictures? - ScienceDirect ScienceDirect The scientific method has been characterized as having two distinct components,  Discovery  and  Justification . Discovery emphasizes ideas and creativity, focuses on conceiving hypotheses and constructing models, and is generally regarded as lacking a formal logic. Justification begins with the hypotheses and models and ends with a valid scientific inference. Unlike Discovery, Justification has a formal logic whose rules must be rigorously followed to produce valid scientific inferences. In particular, when inferences are based on sample data, the rules of the logic of Justification require assessments of bias and precision. Thus, satellite image-based maps that lack such assessments for parameters of populations depicted by the maps may be of little utility for scientific inference; essentially, they may be just pretty pictures. Probability- and model-based approaches are explained, illustrated, and compared for producing inferences for population parameters using a map depicting three land cover classes: non-forest, coniferous forest, and deciduous forest. The maps were constructed using forest inventory data and Landsat imagery. Although a multinomial logistic regression model was used to classify the imagery, the methods for assessing bias and precision can be used with any classification method. For probability-based approaches, the difference estimator was used, and for model-based inference, a bootstrap approach was used. ► Inferences are constructed for parameters of populations depicted by maps. ► Map classes include non-forest, coniferous forest, and deciduous forest. ► Approaches use Landsat and forest inventory data with a logistic regression model. ► Probability-based inference uses simple random sampling and model-assisted estimators. ► Model-based inference uses bootstrap to estimate variances. ► Inferential techniques can be used with any classification technique. Bunge (1967)  asserts that science has a unique goal and a unique method that serve to distinguish it from non-science. With respect to method, he further asserts that “the scientific method is a mark of science,… no scientific method, no science.” In characterizing the scientific method,  Reichenbach (1938)  emphasized the distinction between the context of  Discovery  and the context of  Justification . The starting point for Discovery is an acknowledged problem or gap in the current state of knowledge, and the ending point is one or more hypotheses, models, or solutions proposed to fill the gap. The starting point for Justification is the set of hypotheses, models, or proposed solutions, and the ending point is a valid scientific inference. An important distinction between Discovery and Justification is that whereas Justification has a well-accepted logic, Discovery is a creative enterprise for which no formal logic has been constructed. Strategies that have been used in Discovery include trial and error, systematic search, derivation from theory, illumination of the well-prepared mind, inspiration, serendipity, and more recently, artificial intelligence and data mining ( McRoberts, 1989 ). Within Discovery, there are no right or wrong methods; in fact,  Feyerabend (1975)  asserts that “Anything goes!” Thus, the crux of Discovery is ideas, regardless of how they are generated. The U.S. Forest Service has characterized scientific research as a competition of ideas ( USDA Forest Service, 2000 ), and  Efron (2007)  asserts that “ideas are the coin of the realm in the intellectual world.” Although “Anything goes!” in Discovery, such is decidedly not the case for Justification. The ending point of Justification is a scientific inference, and the logic of inference is formal and well-documented. The relevant Oxford English Dictionary definition of  infer  is “to accept from evidence or premises” ( Simpson  &  Weiner, 1989 ). For most scientific problems, evidence in the form of complete enumerations of populations of interest would be prohibitively expensive, if not physically impossible. Thus, statistical procedures have been developed to infer values for population parameters from estimates based on observations from a sample of population units. In a sampling framework, inference requires expression of the relationship between the population parameter, μ, and its estimate,  μ ˆ μ ˆ , in probabilistic terms ( Dawid, 1983 ). For situations in which the intent is estimation, as opposed to hypothesis testing, these probabilistic expressions often take the form of the familiar 1–α confidence intervals where 1–α denotes the probability that confidence intervals constructed using data for all possible samples will include μ. Of crucial importance, construction of the confidence intervals requires use of the sample data to calculate the estimate,  μ ˆ μ ˆ  and its variance estimate,  V a ˆ r μ ˆ V a ˆ r μ ˆ . Failure to express  μ ˆ μ ˆ  in probabilistic terms through ignorance, neglect, or the inability to estimate  V a ˆ r μ ˆ V a ˆ r μ ˆ  prohibits characterization of the result as a valid scientific inference. For natural resources problems, satellite imagery has become a well-accepted source of landscape information that contributes to the construction of land cover maps. The utility of these maps for scientific inference varies depending on issues of bias and precision.  Card (1982)  cautions that “users will not and should not take a map at face value without some associated estimate of error.”  Switzer (1969)  asserts that a map without an uncertainty assessment puts the user “in a position similar to one who is given a point estimate without any notion of its standard error.” Thus, if bias and precision have not been assessed and reported, regardless of the reason, then maps may have little or no utility for scientific inference. The conclusion, which will certainly be disconcerting and unpleasant to some, is that if estimates of population parameters derived from maps cannot be characterized in probabilistic terms the map cannot serve as a basis for scientific inference; from an inferential perspective, the map may be little more than just a pretty picture. The remote sensing literature is replete with examples of map accuracy assessments based on error matrices and measures such as overall accuracy, users’ and producers’ accuracies, and the Kappa index. However, with only few exceptions ( Czaplewski and Catts, 1992 ,  Gallego, 2004 ,  McRoberts, 2006 ,  McRoberts, 2010a ,  Stehman, 2005 ,  Stehman, 2009 ), these assessments do not provide information on the bias or precision of estimates of parameters such as land cover class proportions or total land cover area for populations depicted by the maps. In a comprehensive review of accuracy assessment methods,  Strahler et al. (2006, p. 39)  note the need for “methods for estimating the accuracy of spatially aggregated products.” The reasons for the lack of literature documentation of bias and precision assessments for estimates of areal population parameters and methods for conducting them are not apparent; perhaps they relate to lack of interest, to lack of expertise, or to lack of methods included in software packages. Regardless of the reasons, descriptions and illustrations of general methods for assessing the bias and uncertainty of estimates of parameters of populations depicted by maps that can be used with any approach to classification are warranted. The objectives of the study are twofold: (1) to distinguish probability-based and model-based inference as they pertain to inferences derived from maps for areal population parameters, and (2) to describe and illustrate methods for assessing bias and precision for both probability- and model-based inference that can be used without regard to the classification method. The context of the analyses is a land cover map that depicts non-forest, coniferous forest, and deciduous forest classes and that was constructed using forest inventory data, Landsat satellite imagery, and a multinomial logistic regression model. The study area was defined by the portion of the row 27, path 27, Landsat scene in northern Minnesota, in the United States of America (USA) ( Fig. 1 ). Land use for the study area consists of forest land dominated by aspen-birch and spruce-fir associations, agriculture, wetlands, and water. Landsat Thematic Mapper (TM) imagery was acquired for three dates corresponding to early, peak, and late seasonal vegetative stages: April 2000, July 2001, and November 1999. Preliminary analyses indicated that the normalized difference vegetation index (NDVI) ( Rouse et al., 1973 ) and the tasseled cap (TC) transformations (brightness, greenness, and wetness) ( Crist and Cicone, 1984 ,  Kauth and Thomas, 1976 ) were superior to both the spectral band data and principal component transformations with respect to predicting the probability of the three land cover classes. Thus, 12 TM-based variables were used, NDVI and the three TC transformations for each of the three image dates. Within the study area, six 15-km × 15-km areas of interest (AOI) were selected using a systematic grid of locations. Fig. 1 . Study area. The Forest Inventory and Analysis (FIA) program of the U.S. Forest Service conducts the national forest inventory of the USA. The program has established field plot centers in permanent locations using a sampling design that produces an equal probability sample ( Bechtold and Patterson, 2005 ,  McRoberts et al., 2005 ). The sampling design is based on a tessellation of the country into approximate 2400-ha (6000-ac) hexagons and features a permanent plot at a randomly selected location within each hexagon. Some states, including Minnesota in which the study area is located, provide additional funding to double the sampling intensity to approximately one plot per 1200 ha. Each FIA plot consists of four 7.32-m (24-ft) radius circular subplots for a total area of 672.45 m 2 . The subplots are configured as a central subplot and three peripheral subplots with centers located at 36.58 m (120 ft) and azimuths of 0 o , 120 o , and 240 o  from the center of the central subplot. In general, locations of forested or previously forested plots are determined using global positioning system receivers, whereas locations of non-forested plots are verified using aerial imagery and digitization methods. The spatial configuration of the FIA subplots with centers separated by 36.58 m and the 30-m × 30-m spatial resolution of the TM /ETM+ imagery permits individual subplots to be associated with individual image pixels. For this study, only data for the central subplots of the FIA plots were used to avoid issues related to lack of independence among observations for subplots of the same plot. Field crews observe species and measure diameter at-breast-height (dbh) (1.37 m, 4.5 ft) and height for all trees with dbh of 12.7 cm (5 in) or greater. Tree data are aggregated at the subplot level to obtain totals for basal area (BA) and other variables. Area and BA by land cover class are obtained for subplots by collapsing ground land use conditions into non-forest and multiple forest classes subject to the FIA definition of forest land: area of at least 0.4 ha (1 ac), continuous crown-to-crown width of at least 36.58 m (120 ft), and stocking of at least 10% where stocking refers to the extent to which the growth potential of a site is used by trees ( Hansen  &  Hahn, 1992 ). For this study, data for subplots that were not completely forested or completely non-forested were not used. In addition, data for subplots that field crews determined to be forested but that had no trees with dbh of 12.7 cm or greater were not used. The 1907 central subplots in the study area, including the 94 subplots in the six AOIs (14–17 subplots per AOI), that satisfied these conditions were measured between 1999 and 2003. For this study, subplots were assigned to three land cover classes: (1)  non-forest  ( NF ) for subplots whose land cover did not qualify as forest land as determined via interpretation of aerial photography or by field crews, (2)  coniferous forest  ( CF ) for forested subplots with proportions of total BA in coniferous trees of at least 0.50, and (3)  deciduous forest  ( DF ) for forested subplots with proportions of total BA in deciduous trees greater than 0.50. Of the 1907 central subplots in the study area, 607 were classified as NF, 604 were classified as CF, and 696 were classified as DF; of the 94 plots in the six AOIs, 24 were classified as NF, 34 were classified as CF, and 36 were classified as DF. A variogram analysis indicated that spatial correlation for cover class observations for central subplots of FIA plots was negligible. All analyses were based on four underlying assumptions: (1) a finite population consisting of N units in the form of 30-m × 30-m TM pixels, (2) an equal probability sample of n population units in the form of observations of the central subplots of FIA plots, (3) ancillary data in the form of the 12 TM-based spectral transformations for each pixel and (4) adequate characterization of the 900-m 2  pixels by the 167.87-m 2  subplots. In the following sections, the terms  population unit  and  pixel  are used interchangeably. Data for accuracy assessments and for estimating the bias and precision of estimators may come from the sample data, a subset of the sample data, or from an independent data set.  Stehman and Czaplewski, 1998 ,  Stehman, 2000 ,  Stehman, 2006 ,  Stehman, 2008 ,  Strahler et al., 2006 ,  McRoberts, 2010b ,  McRoberts et al., 2010  all provide design guidelines and principles for acquiring independent data for accuracy assessment purposes. Although independent data are preferable, their acquisition may not be possible. In addition, splitting the sample data into model calibration and model validation subsets exacerbates the problem of insufficient sample sizes for small areas. Thus, a common alternative is simply to use all the sample data for both model calibration and validation; such is the case for this study. One consequence, however, is that accuracy assessments tend to be optimistic. Two general approaches to classification of satellite images are common,  unsupervised classification  and  supervised classification . With unsupervised classification, pixels are first aggregated into homogenous classes based on their image spectral values. Labels such as NF, CF, and DF are then assigned to the homogeneous classes based on expert opinion, ground observations for pixels in the classes, or other methods. Supervised classification is more sophisticated and entails estimating relationships between the land cover classes and the spectral values of the imagery. For this study, a supervised classification approach based on a multinomial logistic regression model was used. However, the bias and precision assessment methods that are proposed and illustrated are not specific to any particular classification approach. The relationship between a dichotomous dependent variable, Y, and continuous independent variables,  X , is often expressed in the form, p i = f ( X i ; β ) , p i = f ( X i ; β ) , where i indexes population units, p i  is the probability that y i  = 1, and  β  is a vector of parameters to be estimated ( Agresti, 2007 ). The function, f ( X i ; β ), expresses the statistical expectation of Y in terms of  X  and  β  and is often formulated using the logistic function as, (1) p i = f X i ; β = exp ∑ j = 1 J β j x ij 1 + exp ∑ j = 1 J β j x ij , p i = f X i ; β = exp ∑ j = 1 J β j x ij 1 + exp ∑ j = 1 J β j x ij , where j = 1, 2,…, J indexes the independent variables, and exp(.) is the exponential function. The logistic regression model approach can be extended from dichotomous to polychotomous response variables ( Agresti, 2007 ,  McRoberts, 2009 ,  McRoberts, 2010a ). For a response variable with M ≥ 3 classes, one class is selected arbitrarily and designated the Mth class. The estimate of the probability that the ith population unit belongs to the Mth class is, (2a) p ˆ M,i = 1 1 + ∑ m = 1 M − 1 ∑ j = 1 J exp β ˆ mj x ij , p ˆ M,i = 1 1 + ∑ m = 1 M − 1 ∑ j = 1 J exp β ˆ mj x ij , where m indexes the classes of the response variable. The estimate of the probability that the i th  population unit belongs to the mth class (m  <  M) is, (2b) p ˆ m,i = p ˆ M,i exp ∑ j = 1 J β ˆ mj x ij . p ˆ m,i = p ˆ M,i exp ∑ j = 1 J β ˆ mj x ij . All parameters of the multinomial logistic regression model can be estimated simultaneously using a variety of software packages such as SAS with the CATMOD procedure or R with the VGAM library. Probability-based inference is based on three assumptions: (1) population units are selected for the sample using a randomization scheme; (2) the probability of selection for each population unit is positive and known; and (3) the observation of the response variable for each population unit is a constant as opposed to a random variable. Properties of probability-based estimators are based on random variation resulting from the probabilities of selection of population units into the sample, thus the characterization of these estimators as probability-based ( Hansen et al., 1983 ). Although probability-based inference is also characterized as design-based inference, the term  design  is not well-defined in the sense that it may refer simply to the selection of population units into the sample or additionally to the entire inferential process ( Kendall  &  Buckland, 1982 ). With probability-based methods, land cover class observations and predictions are both discrete values of a categorical variable. An error matrix ( Table 1 ) is used to compare numbers of observations and predictions by land cover class and provides the necessary information for four commonly used measures of accuracy:  overall accuracy  (OA), which is the proportion of observations correctly classified;  user ’ s accuracy  (UA), which is the ratio of the number of correct predictions and the total number of predictions for a class; and  producer &# x27;s accuracy  (PA), which is the ratio of the number of correct predictions and the total number of observations for a class. In addition, the  Kappa coefficient  (κ) ( Congalton, 1991 ) is a measure of association describing the agreement between two classifications ( Kraemer, 1983 ). When one classification is based on observations and the other is based on predictions, κ is considered a measure of accuracy and is estimated as, (3) κ ˆ = n ∑ m = 1 M n mm − ∑ m = 1 M n m + · n + m n 2 − ∑ m = 1 M n m + · n + m , κ ˆ = n ∑ m = 1 M n mm − ∑ m = 1 M n m + · n + m n 2 − ∑ m = 1 M n m + · n + m , where n is the number of observations; M is the number of land cover classes; n mm  is the number of population units both observed and predicted to be in the mth land cover class; n m+  and n + m  are the numbers of population units observed in the mth land cover class and predicted to be in the mth land cover class, respectively; and the dot symbol (∙) denotes multiplication. Perfect agreement between the observations and predictions is indicated when  κ ˆ = 1 κ ˆ = 1 , whereas  κ ˆ = 0 κ ˆ = 0  indicates no agreement beyond that expected by chance. An assumption underlying κ is that the land cover class observations and predictions are independent which is not the case for this study. Therefore, estimates of κ for this study are acknowledged to be optimistic. Of crucial importance, a map accuracy assessment does not constitute an inference for a population parameter because it does not directly provide the necessary estimates of bias and precision. Table 1 . Generic error matrix. With probability-based inference, there is no bias or uncertainty for the observed classes of individual population units selected for the sample because the observations are constants, apart from measurement error. No bias assessment for the land cover class predictions for individual population units not selected for the sample is possible apart from bias assessments made for population units in aggregate ( Section 3.2.2 ). Probability-based inference at the areal level relies on the sample data. Further, probability-based inference produces estimates,  μ ˆ μ ˆ , of areal population parameters using estimators that are generally unbiased, although an estimate based on any one sample may deviate considerably from the true value. However, probability-based estimators do not generally produce the same estimates as are obtained by aggregating population unit predictions, and they often do not produce sufficiently precise estimates for small AOIs with small sample sizes. For areal assessment of maps, the objective is typically to estimate population parameters such as the total area or proportion of a land cover class. Because the estimate of the total area of a class is simply the product of total area which is usually known and the estimate of the class proportion, the focus of this study is estimation of the proportion. For the mth land cover class, define, y m,i = { 1 if class m is observed for the i th  population unit 0 if class m is not observed for the i th  population unit ; y m,i = { 1 if class m is observed for the i th  population unit 0 if class m is not observed for the i th  population unit ; and, y ˆ m , i = { 1 if class m is predicted for the i th  population unit 0 if class m is not predicted for the i th  population unit . y ˆ m , i = { 1 if class m is predicted for the i th  population unit 0 if class m is not predicted for the i th  population unit . For sampling designs with equal probabilities of selection for each population unit, the simplest approach to probability-based areal inference for the proportion, μ m , of an AOI with map class m is to use the familiar simple random sampling (SRS) estimators: (4) μ ˆ m,SRS = 1 n ∑ i = 1 n y m,i , μ ˆ m,SRS = 1 n ∑ i = 1 n y m,i , and, (5) V a ˆ r μ ˆ m,SRS = μ ˆ m,SRS 1 − μ ˆ m,SRS n , V a ˆ r μ ˆ m,SRS = μ ˆ m,SRS 1 − μ ˆ m,SRS n , where i indexes the n sample observations and y m,i  is the observation for the ith population unit. Probability-based areal inference consists of inferring μ m  from the sample observations as  μ ˆ m,SRS ± t V a ˆ r μ ˆ m,SRS μ ˆ m,SRS ± t V a ˆ r μ ˆ m,SRS  where t ≈ 2.0 produces an approximate 95% confidence interval. For this study, finite population correction factors are ignored for these estimators because the sampling intensity is very small, on the order of 1:144,000. In addition, although the SRS variance estimators are known to be biased when used with systematic sampling designs, the bias is conservative in the sense that the estimators over-estimate the true variances ( Särndal et al., 1992 ). The advantages of SRS estimators are that they are intuitive, familiar, and simple; the primary disadvantage is that they often produce large variance estimates, particularly for small areas with small sample sizes. Model-assisted estimators rely on observations for population units selected for the sample and model predictions for population units not selected for the sample. However, because the validity of an inference is still based on the probability sample, the estimator is characterized as probability-based.  Stehman (2009)  provides an excellent discussion of the conceptual framework underlying the relationship between model-assisted estimators and map accuracy assessments. For equal probability samples, a naïve model-assisted estimator of the population proportion, μ m , for the mth land cover class, is, μ ˆ m,naive = 1 N ( ∑ i = 1 n y m,i + ∑ i = n + 1 N y ˆ m,i ) , μ ˆ m,naive = 1 N ( ∑ i = 1 n y m,i + ∑ i = n + 1 N y ˆ m,i ) , where the population has been indexed so that i = 1,2,…,n denotes the sampled population units with observations, y m,i , and i = n + 1,n + 2,…,N denotes the remaining population units with predictions,  y ˆ m,i y ˆ m,i . The bias of this estimator can be estimated as, (6) Bias ˆ μ ˆ m,naive = 1 n ∑ i = 1 n y ˆ m,i − y m,i = n + m − n m + n , Bias ˆ μ ˆ m,naive = 1 n ∑ i = 1 n y ˆ m,i − y m,i = n + m − n m + n , where n + m  and n m+  are obtained from the error matrix ( Table 1 ) ( McRoberts, 2010 ). The model-assisted difference estimator ( Baffetta et al., 2009 ,  Särndal et al., 1992 ) is defined as the difference between the naïve estimator and its bias estimate, (7a) μ ˆ m,Dif = 1 N ∑ i = 1 n y m,i + ∑ i = n + 1 N y ˆ m,i − 1 n ∑ i = 1 n y ˆ m,i − y m,i , μ ˆ m,Dif = 1 N ∑ i = 1 n y m,i + ∑ i = n + 1 N y ˆ m,i − 1 n ∑ i = 1 n y ˆ m,i − y m,i , which can be approximated as, (7b) μ ˆ m,Dif = 1 N ∑ i = 1 N y ˆ m,i − n + m − n m + n , μ ˆ m,Dif = 1 N ∑ i = 1 N y ˆ m,i − n + m − n m + n , ( McRoberts, 2010 ). The variance of  μ ˆ m,Dif μ ˆ m,Dif  can be approximated as, (8) V a ˆ r μ ˆ m,Dif = 1 n n − 1 ∑ i = 1 n y ˆ m,i − y m,i 2 = n + m + n m + − 2 n mm n n − 1 , V a ˆ r μ ˆ m,Dif = 1 n n − 1 ∑ i = 1 n y ˆ m,i − y m,i 2 = n + m + n m + − 2 n mm n n − 1 , ( McRoberts, 2010 ) where n + m , n m+ , and n mm  are again obtained from the error matrix ( Table 1 ). Thus, although error matrices do not constitute inferences and do not directly assess bias and precision of population parameters, they do provide much of the information necessary for doing so when using the model-assisted difference estimator. The primary advantage of model-assisted estimators is that they have the potential to capitalize on the relationship between the land cover class observations and their predictions to reduce the variance of the population parameter estimate. However, as with all probability-based estimators, model-assisted estimators often suffer the effects of small sample sizes when used for small area estimation. With model-based inference, a model is used to produce predictions for all population units. Although model-based estimators are often more computationally intense, they produce maps as by-products; they produce estimates that are compatible with maps in that the estimates are calculated by aggregating population unit predictions; they may produce viable estimates for small areas; but they cannot be assumed to be unbiased. Model-based approaches to inference are based on the assumption of an entire distribution of possible observations for Y for each population unit, not just a single constant value as is the case for probability-based inference. This conceptual framework of a distribution of possible values for each population unit is often characterized as a superpopulation ( Graubard and Korn, 2002 ,  Rennolls, 1982 ). Whereas randomization for probability-based inference enters through the random selection of population units into the sample, randomization for model-based inference enters through the random realization of observations from the distributions for individual population units selected for the sample. Thus, model-based inference is often characterized as conditional on the sample. Current approaches to model-based inference originated in the context of survey sampling and can be attributed to  Mátern, 1960 ,  Brewer, 1963 ,  Royall, 1970 . Given the origins of model-based inference in survey sampling, it is not surprising that forestry applications have often been in the context of forest inventory ( Gregoire, 1998 ,  Kangas, 2006 ,  Mandallaz, 2008 ,  Rennolls, 1982 ). An important aspect of the model-based approach is that when the model is correctly specified, the estimator is unbiased ( Lohr, 1999 ); however, when the model is misspecified, the adverse effects on inference may be substantial ( Hansen et al., 1983 ,  Royall and Herson, 1973 ). Thus, much of the reported research on model-based inference has focused on selection of sampling designs and estimators that are robust to model misspecification ( Chambers, 2003 ,  Valliant et al., 2000 ). The mean and standard deviation of the distribution of Y m  for the ith population unit may be denoted μ m,i  and σ m,i , respectively. For model-based inference, an observation, y m,i , for the ith population unit is expressed as, y m,i = μ m,i + ε m,i , y m,i = μ m,i + ε m,i , where ε m,i  is the random deviation of the observation, y m,i , from its mean, μ m,i . The mean, μ m,i , is expressed mathematically as, μ m,i = f X i ; β , μ m,i = f X i ; β , and the model, y m,i = f X i ; β + ε m,i , y m,i = f X i ; β + ε m,i , is fit to the sample data where  X i  is the vector of ancillary variables associated with the ith population unit, and  β  is a vector of parameters to be estimated. With model-based approaches, estimation often focuses on the mean, μ m,i , rather than the particular observed land cover class, y m,i , which is a random realization from the distribution of which μ m,i  is the mean. With the multinomial logistic regression model, μ m,i  is estimated as  μ ˆ m,i = p ˆ m.i μ ˆ m,i = p ˆ m.i  from Eqs.  (2a) ,  (2b) . A crucial component of bias assessment for model-based approaches is an evaluation of the quality of fit of the model to the data as a means of assessing the adequacy of the model specification ( Section 4.2 ). With model-based approaches, there are no correct or incorrect land cover class predictions because the class observations are random realizations from distributions of possible observations. Therefore, error matrices and accuracy measures such as OA, UA, PA, and κ are not relevant for model-based approaches. However, whereas there is no uncertainty in land cover class observations for sample population units with the probability-based approach because observations are constants, such uncertainty does exist with model-based approaches because observations are realizations of random variables. Depending on the modelling approach, parametric methods for estimating the uncertainty of  μ ˆ m,i μ ˆ m,i  for individual population units may be possible. For a binomial logistic regression model,  McRoberts, 2006 ,  McRoberts, 2010a  describe and illustrate a parametric method using Taylors series approximations for estimating variances. However, an appropriate approach for M ≥ 3 is more complex and is highly dependent on the mathematical form of the model. Therefore, a more generic approach such as bootstrap resampling could be considered ( Section 3.3.3 ). With model-based inference, the population mean, μ m , is estimated as, (9) μ ˆ m,Mod = 1 N ∑ i = 1 N μ ˆ m,i = 1 N ∑ i = 1 N f X i ; β ˆ , μ ˆ m,Mod = 1 N ∑ i = 1 N μ ˆ m,i = 1 N ∑ i = 1 N f X i ; β ˆ , where the subscript  Mod  denotes an estimator for model-based inference. With the model-based approach,  μ ˆ m,Mod μ ˆ m,Mod  is compatible with the map, whereas estimates based on probability-based estimators may differ considerably from  μ ˆ m,Mod μ ˆ m,Mod . The general form of an estimator of the variance of  μ ˆ m,Mod μ ˆ m,Mod  is, V a ˆ r μ ˆ m,Mod = 1 N 2 ∑ i = 1 N V a ˆ r μ ˆ m,i + 2 ∑ i < N ∑ j N C o ˆ v μ ˆ m,i , μ ˆ m,j V a ˆ r μ ˆ m,Mod = 1 N 2 ∑ i = 1 N V a ˆ r μ ˆ m,i + 2 ∑ i < N ∑ j N C o ˆ v μ ˆ m,i , μ ˆ m,j ( McRoberts, 2006 ,  McRoberts, 2010a ). Calculation of  V a ˆ r μ ˆ m,i V a ˆ r μ ˆ m,i  and  C o ˆ v μ ˆ m,i , μ ˆ m,j C o ˆ v μ ˆ m,i , μ ˆ m,j  is complex, highly dependent on the mathematical form of the model, and possibly computationally intensive. Thus, resampling approaches to estimating  Var μ ˆ m,Mod Var μ ˆ m,Mod  also merit consideration ( Section 3.3.3 ). Resampling procedures such as the bootstrap are well-suited for complex and non-parametric model applications and for applications requiring assumptions whose validity is difficult to assess. The bootstrap resampling procedure was invented by  Efron, 1979 ,  Efron, 1981 ,  Efron, 1982  and further developed by  Efron and Tibshirani (1994) . All bootstrap methods depend on the notion of a  bootstrap sample . For regression problems,  Efron and Tibshirani (1994)  describe three approaches to constructing a bootstrap sample. First, for a sample of n pairs (y i ,  X i ) and the corresponding empirical distribution of the pairs, each with probability 1/n, a bootstrap sample is defined to be a sample of size n drawn with replacement from the empirical distribution. This approach is characterized as  bootstrapping pairs . The pairs can also be expressed as ( y ˆ i y ˆ i  + ε i , X i ) where  ε i = y i − y ˆ i ε i = y i − y ˆ i . The second and third approaches to bootstrapping focus on resampling the residuals, ε, and are characterized as  bootstrapping residuals . The second approach draws a random sample with replacement from the empirical distribution of residuals and adds them back to the model predictions to form a bootstrap sample. The third approach draws the sample of residuals from a parametric model of the residual distribution. Assumptions underlying all bootstrapping approaches are that the resampling mimics the original sampling features such as clustering and the original data features such as heteroscedasticity and that both observations and residuals are independently and identically distributed (iid). In the case of heteroscedasticity, either the residuals must be studentized by dividing them by their respective standard deviations before resampling or the bootstrapping procedure must incorporate heteroscedasticity. For model-based inference, randomization occurs in the realization of observations from the distribution for each population unit rather than randomization in the selection of population units into the sample. Thus, for model-based inference, bootstrapping residuals is the more intuitive approach, although the iid assumption may be difficult to accommodate. Efron and Tibshirani (1994, page 113)  comment that bootstrapping residuals is more sensitive to assumptions than bootstrapping pairs for which the only assumption is that the original pairs represent a random sample from the population of interest. However, they further note that when bootstrapping pairs, the results approach those obtained when bootstrapping residuals as n increases. Regardless of the bootstrapping approach selected, the model is refit to the kth bootstrap sample, estimates are calculated for each population unit, and the population estimate,  μ ˆ boot k μ ˆ boot k , is calculated using Eq.  (9) . The overall bootstrap population estimate is then, (10) μ ˆ boot = 1 n boot ∑ k = 1 n boot μ ˆ boot k , μ ˆ boot = 1 n boot ∑ k = 1 n boot μ ˆ boot k , where n boot  is the number of bootstrap samples. The bootstrap estimate of bias is defined as, (11) Bias ˆ boot μ ˆ = μ ˆ boot − μ ˆ Bias ˆ boot μ ˆ = μ ˆ boot − μ ˆ where  μ ˆ μ ˆ  is the estimate obtained from the original sample. Of particular importance, this bias estimate pertains only to sampling issues; it does not address model misspecification. The bootstrap estimate of variance is calculated as, (12) Var boot μ ˆ ˆ = 1 n boot − 1 ∑ k = 1 n boot μ ˆ boot k − μ ˆ boot 2 . Var boot μ ˆ ˆ = 1 n boot − 1 ∑ k = 1 n boot μ ˆ boot k − μ ˆ boot 2 . For both the model-assisted and model-based approaches to inference, observations and TM data for the 1907 central subplots were used to estimate the parameters of the multinomial logistic regression model. A variogram analysis of studentized residuals indicated negligible spatial correlation. The model was then applied to the six AOIs using model parameter estimates based on the sample from the entire study area. Thus, both the model-assisted difference estimator and the model-based estimator are characterized as  synthetic  because they use data external to the AOIs to which they are applied ( Gonzalez, 1973 ). For each pixel in each AOI, the class, m, for which  p ˆ m,i p ˆ m,i  from Eqs.  (2a) ,  (2b)  was the largest was assigned. For all subplots in the study area and for all subplots in the aggregation of the six AOIs, error matrices corresponding to sample observations and corresponding predictions were constructed ( Table 1 ), and OA, PA, UA, and  κ ˆ κ ˆ  were calculated. For each class, m, and for each AOI and the aggregation of the six AOIs, the SRS estimates,  μ ˆ m,SRS μ ˆ m,SRS  and  V a ˆ r μ ˆ m,SRS V a ˆ r μ ˆ m,SRS , were calculated using only observations for subplots with centers in the AOIs. The SRS estimates served as the standard for comparison for the other estimators. In addition, for each class, m, and for each AOI and the aggregation of the six AOIs,  μ ˆ m,Dif μ ˆ m,Dif ,  V a ˆ r μ ˆ m,Dif V a ˆ r μ ˆ m,Dif , and  Bias ˆ μ ˆ m,naive Bias ˆ μ ˆ m,naive  were calculated with the constraint that the last two estimates were based only data for subplots with centers in the AOIs. For each pixel and for m = 1 (NF), m = 2 (CF), and m = 3 (DF),  μ ˆ m,i = p ˆ m,i μ ˆ m,i = p ˆ m,i  was calculated, and for each AOI and the aggregation of the six AOIs,  μ ˆ NF,Mod μ ˆ NF,Mod ,  μ ˆ CF,Mod μ ˆ CF,Mod , and  μ ˆ DF,Mod μ ˆ DF,Mod  were calculated. Because the issue of bias for model-based estimators is closely linked to correct model specification, the approach to assessing pixel-level bias focused on assessing the quality of fit of the model to the data at the subplot/pixel level. If the model is correctly specified, a graph of observations versus model predictions for a continuous response variable should feature points that lie along a line with intercept 0 and slope 1. However, because the data used to estimate the model parameters for this study are polychotomous, a slightly modified three-step approach was used: (1) all subplot observation/pixel model prediction pairs, (y mi ,  μ ˆ mi μ ˆ mi ), were ordered with respect to  μ ˆ mi μ ˆ mi ; (2) the ordered pairs were grouped into categories of equal numbers of pairs, and the group means of the subplot observations and of the pixel model predictions were calculated; and (3) a graph of the observation means versus the model prediction means was constructed. In the absence of model lack of fit a graph of the points defined by the corresponding group means of observations and group means of model predictions should lie along the 1:1 line and a simple linear model fit to the points should have intercept of approximately 0 and slope of approximately 1. For both binomial and multinomial logistic regression models, bootstrapping residuals using the empirical distribution of residuals is not feasible ( Appendix A ). However, both the bootstrapping pairs approach and the parametric approach to bootstrapping residuals were used. For both approaches, bootstrap resamples of size n = 1907 were selected with replacement. For the parametric approach to bootstrapping residuals, a modification as per  Lin et al., 2009 ,  Mittlböck and Schemper, 2002  was used to accommodate the polychotomous distribution of the data and the heterogeneous residual variances. For each bootstrap sample, a random number, r, was drawn from a uniform (0,1) distribution for the ith population unit in the sample, and a bootstrap observation,  y ˜ i y ˜ i , was generated by assigning a land cover class to the unit as, y ˜ i = { 1 ( NF ) if 0 ≤ r ≤ μ ˆ NF,i 2 ( CF ) if μ ˆ NF,i < r ≤ μ ˆ NF,i + μ ˆ CF,i 3 ( DF ) if μ ˆ NF,i + μ ˆ CF,i < r ≤ 1 , y ˜ i = { 1 ( NF ) if 0 ≤ r ≤ μ ˆ NF,i 2 ( CF ) if μ ˆ NF,i < r ≤ μ ˆ NF,i + μ ˆ CF,i 3 ( DF ) if μ ˆ NF,i + μ ˆ CF,i < r ≤ 1 , where  μ ˆ NF,i μ ˆ NF,i ,  μ ˆ CF,i μ ˆ CF,i ,and  μ ˆ DF,i μ ˆ DF,i  were calculated using parameters estimated from the original data.  Efron and Tibshirani (1994)  recommend at least n boot  = 200 bootstrap samples. For this study, bootstrap resampling and calculation of  Bias boot ˆ μ ˆ Bias boot ˆ μ ˆ  from Eq.  (11)  and  SE boot μ ˆ = V a ˆ r boot μ ˆ SE boot μ ˆ = V a ˆ r boot μ ˆ  from Eq.  (12)  continued until  SE boot μ ˆ SE boot μ ˆ  stabilized. Bootstrap estimates,  Bias boot ˆ μ ˆ Bias boot ˆ μ ˆ  and  SE boot μ ˆ SE boot μ ˆ , were calculated for each of the six AOIs and the aggregation of the six AOIs. Results of accuracy assessments for all subplots in the entire study area and for only the subplots in the six AOIs were similar ( Table 2a ,  Table 2b ). For both datasets, PA, UA, and OA were small relative to the general preference for accuracies of 0.85 or greater ( Anderson et al., 1976 ). However, the results are similar to those obtained by  McRoberts (2009)  who used similar data to compare multinomial logistic regression, disciminant analysis, and the k-Nearest Neighbors techniques. Multiple reasons can be advanced to explain these results. First, the CF and DF classes are not intrinsically discrete classes but rather are distinguished by a threshold for a continuous variable, BA. Thus, confusion between the CF and DF classes for BA ≈ 0.5 should be expected. Second, for GPS receivers of the type used by the FIA program, as many as half the subplots could be associated with an incorrect pixel ( McRoberts, 2010b ). Third, tree density on forest subplots varies considerably, even though the entire subplot is characterized as forest. Thus, completely forested subplots with sparse tree cover may be predicted to have smaller probabilities for the CF and DF classes than forested subplots with dense tree cover. Fourth, spectral differences for subplots with similar tree densities but different age structures or health conditions may produce different estimates for land cover classes. Fifth, subplots with tree cover may be characterized as NF if the minimum FIA requirements of a 0.4-ha patch with 36.58-m width and 10% stocking are not satisfied. Sixth, the observation for the smaller subplot may not adequately characterize the larger pixel. However, when the CF and DF classes were aggregated into a single forest class, forest/non-forest accuracy assessments produced OA = 0.88 for all subplots in the study area and OA = 0.89 for only the subplots in the six AOIs. These latter OAs were similar to those reported elsewhere for forest/non-forest classifications based on similar data but using different classification methods ( Finley et al., 2008 ,  Haapanen et al., 2004 ). These results suggest the primary cause for the relatively low accuracies may be due to the inability to distinguish the CF and DF classes, particularly for BA ≈ 0.5. Table 2a . Error matrix for all central subplots in study area. Table 2b . Error matrix for all central subplots in six AOIs. The SRS and model-assisted difference estimates of means were similar for the aggregation of the six AOIs but deviated substantially for some individual AOIs ( Table 3 ). For the aggregation of the six AOIs, the model-assisted difference estimates were within two SRS standard errors of the SRS means. The standard errors for model-assisted difference estimates were generally, although not always, smaller than the SRS estimates, a result that reflects the quality of the class predictions obtained from the model. However, the naïve bias estimates for the model-assisted approach were as large in absolute value as 0.18 for individual AOIs. This result may be attributed to the relatively small numbers of subplots in the AOIs. For example, with only 14–17 subplots in each AOI, each misclassified plot has the potential to increase the naïve bias estimate by approximately 0.07. As expected, the naive bias estimates were smaller for the aggregation of the six AOIs, ranging in absolute value from 0.01 to 0.05. Table 3 . Estimates for six 15-km × 15-km AOIs individually and in aggregate. Bias of naïve estimator incorporated into difference estimate of mean. Bias not incorporated into estimate of mean. Graphs of the means of ordered groups of observations versus means of corresponding ordered groups of predictions suggested adequate fit of the model to the data and, therefore, little model misspecification ( Fig. 2 a,b,c). Simple linear models fit to the grouped data yielded  α ˆ NF = 0.011 α ˆ NF = 0.011 ,  α ˆ CF = 0.008 α ˆ CF = 0.008 , and  α ˆ DF = 0.017 α ˆ DF = 0.017  as estimates of the intercepts and  β ˆ NF = 0.966 β ˆ NF = 0.966 ,  β ˆ CF = 0.975 β ˆ CF = 0.975 , and  β ˆ DF = 0.952 β ˆ DF = 0.952  as estimates of the slopes. All these pairs of estimates are very similar to α = 0 and β = 1 as would be expected for correct model specification. Fig. 2 . a. Estimated probabilities of non-forest (NF) from Eqs.  (2a) ,  (2b) . b. Estimated probability of coniferous forest (CF) from Eqs.  (2a) ,  (2b) . c. Estimated probability of deciduous forest (DF) from Eqs.  (2a) ,  (2b) . For the aggregation of the six AOIs,  SE boot μ ˆ SE boot μ ˆ  stabilized for n boot  = 300 for the parametric approach to bootstrapping residuals, but n boot  = 500 was necessary for  SE boot μ ˆ SE boot μ ˆ  to stabilize for the bootstrapping pairs approach ( Fig. 3 a,b). For individual AOIs, similar results were obtained. Although stabilization for the same values of n boot  for individual AOIs as for the aggregation of the six AOIs may seem counter-intuitive, estimates for the multinomial logistic regression model used for estimating  μ ˆ Mod,m μ ˆ Mod,m  for the individual AOIs were based on the same number of subplots and the same bootstrap observations as were used for estimating  μ ˆ Mod,m μ ˆ Mod,m  for the aggregation of the six AOIs. Fig. 3 . a. Bootstrap standard error versus number of bootstrap samples for aggregation of six AOIs using bootstrapping pairs. b. Bootstrap standard error versus number of bootstrap samples for aggregation of six AOIs using parametric bootstrapping residuals. The model-based estimates of the mean,  μ ˆ Mod μ ˆ Mod , were all within two SRS standard errors of the SRS estimates,  μ ˆ SRS μ ˆ SRS , except for the single case for which  SE μ ˆ SRS = 0 SE μ ˆ SRS = 0 . The two bootstrapping approaches produced very similar estimates of  SE boot μ ˆ SE boot μ ˆ  for both individual AOIs and the aggregation of the six AOIs. This result confirms the assertion of  Efron and Tibshirani (1994, page 113)  that results for bootstrapping pairs should approach results for bootstrapping residuals for large n. Although a comparison of the two sets of model-based standard errors to the two sets of probability-based standard errors is enticing, the two inferential approaches are based on such different underlying assumptions that such a comparison would be conceptually meaningless. Bootstrap estimates of bias,  Bias ˆ boot μ ˆ Bias ˆ boot μ ˆ , for the two approaches were nearly the same and essentially negligible. However, as previously noted,  Bias ˆ boot μ ˆ Bias ˆ boot μ ˆ  does not assess model misspecification which is why separate analyses to assess model lack of fit are necessary ( Fig. 2 a,b,c). Model-based estimates of variances and standard errors for logistic regression models depend heavily on estimates of parameter variances and covariances which, in turn, depend heavily on sample sizes. Thus, if the sample size used for estimating model parameters is doubled, standard errors would be expected to decrease by a multiplicative factor of  1 2 1 2 , whereas if the sample size were only half, standard errors would be expected to increase by a multiplicative factor of  2 2 . This effect is reflected in the bootstrapping procedure in that parameters estimated from smaller or larger bootstrap samples would exhibit greater or lesser variability, respectively. Multiple conclusions may be drawn from the study. First, for the aggregation of the six AOIs, the two probability-based approaches and the model-based approach produced similar estimates of proportions for the three land cover classes. However, the estimates differed considerably for the individual AOIs. In particular, as per  Särndal et al. (1992, page 223) , the model-assisted difference estimator should not be used for small sample sizes or unless classification accuracies are very large. Nevertheless, for areas with larger sample sizes such as the aggregation of the six AOIs, the model-assisted difference estimator can be used with any classification approach to produce valid statistical inferences. Second, the two bootstrapping approaches to estimating standard errors for the model-based approach produced nearly identical results and confirm the assertion of  Efron and Tibshirani (1994) . This finding indicates that bootstrapping pairs, for which underlying assumptions are minimal, can be used with classification approaches for which bootstrapping residuals is difficult or impossible. In particular, bootstrapping pairs, in conjunction with an assessment of model lack of fit, provides a mechanism leading to a valid model-based inference for any approach used to obtain areal population estimates. In summary, methods producing both valid probability-based and model-based inferences, regardless of the classification or estimation approach, were described and illustrated. These methods are sufficient to move a map from simply a pretty picture to a basis for scientific inference and to move a map-based estimation effort from Discovery to Justification. An assumption underlying bootstrapping of residuals is that the residuals are independently and identically (iid) distributed. Thus, in the presence of heteroscedasticity, the residuals must be studentized by dividing them by estimates of their standard deviations. For a binomial variable, studentized residuals are of the form, ε i s i = y i − p ˆ i p ˆ i 1 − p ˆ i = { 1 − p ˆ i p ˆ i 1 − p ˆ i = 1 − p ˆ i p ˆ i if y i = 1 0 − p ˆ i p ˆ i 1 − p ˆ i = − p ˆ i 1 − p ˆ i if y i = 0 . ε i s i = y i − p ˆ i p ˆ i 1 − p ˆ i = { 1 − p ˆ i p ˆ i 1 − p ˆ i = 1 − p ˆ i p ˆ i if y i = 1 0 − p ˆ i p ˆ i 1 − p ˆ i = − p ˆ i 1 − p ˆ i if y i = 0 . Thus, the studentized residual corresponding to any particular observation can take on only one of two values, depending on y i . A simple example shows that the process of re-assigning residuals to model predictions leads to erroneous results. For y i  = 1 and  p ˆ i = 0.75 p ˆ i = 0.75 , the studentized residual is  ε i s i = 1 − p ˆ i p ˆ i = 0.25 0.75 ≈ 1.73 ε i s i = 1 − p ˆ i p ˆ i = 0.25 0.75 ≈ 1.73 . If this studentized residual is re-assigned to a prediction,  p ˆ j = 0.33 p ˆ j = 0.33  with  s j = p ˆ j 1 − p ˆ j ≈ 0.47 s j = p ˆ j 1 − p ˆ j ≈ 0.47 , the bootstrap observation becomes, y ˜ j = p ˆ j + s j ε i s i ≈ 0.33 + 0.47 1.73 ≈ 1.14 , y ˜ j = p ˆ j + s j ε i s i ≈ 0.33 + 0.47 1.73 ≈ 1.14 , which is impossible because y j  must be either 0 or 1. Similar results occur for a multinomial approach. We use cookies to help provide and enhance our service and tailor content and ads. By continuing you agree to the  use of cookies . Copyright © 2019 Elsevier B.V. or its licensors or contributors. ScienceDirect ® is a registered trademark of Elsevier B.V. 