{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from html.parser import HTMLParser\n",
    "import nltk\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HtmlHandler(HTMLParser):\n",
    "    def reset(self):\n",
    "        self.inTitle = False\n",
    "        self.inPara = False\n",
    "        self.result = \"\"\n",
    "        self.ret = \"\"\n",
    "        HTMLParser.reset(self)\n",
    "    \n",
    "    def handle_starttag(self, tag, attrs):\n",
    "        if tag == \"title\":\n",
    "            self.inTitle = True\n",
    "        elif tag == \"p\":\n",
    "            self.inPara = True\n",
    "        # print(\"Encountered a start tag:\", tag)\n",
    "\n",
    "    def handle_endtag(self, tag):\n",
    "        if tag == \"title\":\n",
    "            self.inTitle = False\n",
    "        elif tag == \"p\":\n",
    "            self.inPara = False\n",
    "        # print(\"Encountered an end tag :\", tag)\n",
    "\n",
    "    def handle_data(self, data):\n",
    "        pflag = False\n",
    "        if self.inTitle or self.inPara:\n",
    "            for c in data:\n",
    "                if c != ' ' and c != '' and c != '\\n' and c != '\\t':\n",
    "                    pflag = True\n",
    "                    break\n",
    "            if pflag:\n",
    "                self.result += data\n",
    "                self.result += \" \"\n",
    "        # print(\"Encountered some data  :\", data)\n",
    "    \n",
    "    def ret_result(self):\n",
    "        for c in self.result:\n",
    "            if c != '\\n' and c != '\\t':\n",
    "                self.ret += c\n",
    "        return self.ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def html2vec(file_path, word2idx):\n",
    "    '''\n",
    "    parameters:\n",
    "    file_path: input html file path\n",
    "    word2idx: fetched from trained doc2vec model, see doc2vec_clean.ipynb\n",
    "    \n",
    "    return:\n",
    "    ret_vector: unpadded vector, requires padding\n",
    "    '''\n",
    "    ret_vector = []\n",
    "    english_punctuations = ['|', '-', '·', '``', ',', '.', ':', ';', '?', '(', ')', '[', ']', '<', '>', '&', '!', '*', '@', '#', '$', '%', '...', \"'\", '\"', \"--\", \"`\", \"“\", \"”\", \"’\", \"‘\", \"_\", \"''\", '+', '*', '/', '\\\\', '=', '~', '^', '{', '}']\n",
    "    Handler = HtmlHandler()\n",
    "    Handler.reset()\n",
    "    f = open(file_path, 'r')\n",
    "    html = \"\"\n",
    "    for tmp in f.readlines():\n",
    "        tmp.strip('\\n')\n",
    "        html += tmp\n",
    "    f.close()\n",
    "    Handler.feed(html)\n",
    "    result = Handler.ret_result()\n",
    "    result = nltk.word_tokenize(result)\n",
    "    result = [word.lower() for word in result if word not in english_punctuations]\n",
    "    for word in result:\n",
    "        if word in word2idx.keys():\n",
    "            ret_vector.append(word2idx[word])\n",
    "    return ret_vector"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
