Supervised EEG Ocular Artefact Correction Through Eye-Tracking | SpringerLink This service is more advanced with JavaScript available, learn more at  http://activatejavascript.org Advertisement Advances in Neurotechnology, Electronics and Informatics                 pp 99-113  |                 Cite as Electroencephalography (EEG) is a widely used brain signal recording technique with many uses. The information conveyed in these recordings is a useful tool in the diagnosis of some diseases and disturbances, basic science, as well as in the development of non-invasive Brain-Machine Interfaces (BMI). However, the electrical recording setup comes with two major downsides, a. poor signal-to-noise ratio and b. the vulnerability to any external and internal noise sources. One of the main sources of artefacts is eye movements due to the electric dipole between the cornea and the retina. We have previously proposed that monitoring eye-movements provides a complementary signal for BMIs. Here we propose a novel technique to remove eye-related artefacts from the EEG recordings. We coupled Eye Tracking with EEG allowing us to independently measure when ocular artefact events occur through the eye tracker and thus clean them up in a targeted “supervised” manner instead of using a “blind” artefact clean up correction technique. Three standard methods of artefact correction were applied in an event-driven, supervised manner: 1. Independent Components Analysis (ICA), 2. Wiener Filter and 3. Wavelet Decomposition and compared to “blind” unsupervised ICA clean up. These are standard artefact correction approaches implemented in many toolboxes and experimental EEG systems and could easily be applied by their users in an event-driven manner. Already the qualitative inspection of the clean up traces shows that the simple targeted artefact event-driven clean up outperforms the traditional “blind” clean up approaches. We conclude that this justifies the small extra effort of performing simultaneous eye tracking with any EEG recording to enable simple, but targeted, automatic artefact removal that preserves more of the original signal. Electroencephalogram (EEG) recordings are widely used for different neurological applications, such as diagnosis of epilepsy or sleep disorders, or brain machine interfaces [ 1 ,  2 ,  3 ]. The EEG trace is known to be highly variable, in part due to transient physiological conditions and state of the brain as well as noise inside the nervous system (e.g. [ 4 ,  5 ,  6 ], for general overview see [ 7 ]) but mainly due to noise and artefacts from any kind of non-neuronal generated electromagnetic fields. Noise artefacts are caused by external (e.g. AC line noise, mobile phones, electric motors) or biological electromagnetic activity from muscle contractions of the face and the eyes, as well as movement of the eye-ball itself. Ocular artefacts are most relevant since the influence of the eye dipole (potential difference between the Retinal Pigment Epithelium and the cornea) in the recording is very high, due to the proximity to the electrodes. The influence of eye blinks specifically is very high as it causes a large change in the signal, both due to the influence of the eye lid and the reflex rotation of the eye ball downwards and inwards [ 8 ]. Eye Tracking technology, and mostly the video-based recording of eye gaze, have recently become by a factor of up to 1,000 less costly [ 9 ] and rapid “walk-up” calibration [ 10 ] is enabling this technology to be more widely used in several applications (e.g. medical diagnostics or robotic control). Moreover, video-based eye tracking is not affected by external electrical fields and as such is independent from EEG noise sources. Most of the current approaches to Ocular Artefact removal are “blind” and include removal of blink regions [ 11 ], wavelet decomposition [ 12 ], Independent Components Analysis [ 13 ] or use Electrooculogram recordings (EOG) to then subtract this from the EEG [ 14 ]. “Blind” approaches have the downfall of the artefact removal being performed generically to the whole signal, so there is a step in identifying what is and what is not an artefact, which is prone to error. By having an eye tracking recording we eliminate this error and are sure of when an artefact is ocurring. Moreover, it enables the specific ocular artefacts to be characterised for use in other removal approaches, such as the Wiener filter. In this study we use the Eye Tracking information to detect regions of Ocular Artefacts and use that to perform local correction, thus minimizing the influence of the corrective measures in the rest of the signal. This will provide a non corrupted but clean signal, that can then be used in EEG applications such as Brain Machine Interfaces or Medical Diagnosis. Experimental Setup.  1  is the eye tracker,  2  is the stimuli screen and  3  is the electrode cap Eye Tracking was performed with an SMI Red-m Eye Tracker (SensoMotoric Instruments GmbH, Teltow, Germany), a binocular, remotely mounted Eye Tracker. EEG data was collected with a BrainProducts ActiCHamp amplifier and a 32 active-electrode set with an ActiCap (Brain Products GmbH, Gilching, Germany). Eye Tracking was performed at 120 Hz and EEG recordings were sampled at 500 Hz. Impedance of Electrodes against the skin was reduced to levels always below 15 kΩ, to ensure EEG signal quality. Eye Tracking was performed at a distance of 50–70 cm from the cameras. The EEG data was then pre-processed by a bandpass filter between 0.1–50 Hz, resampled to 120 Hz and Common Average Re-referenced. Eye Gaze data (retrieved from the Eye Tracker) was used to find blink regions and extract blink markers. The task was set up in Matlab with the help of the PsychoPhysics Toolbox [ 15 ]. Participants were asked to sit at a distance of 50–70 cm from the Eye Tracker and Monitor, to ensure tracking (as per the Eye Tracker’s technical information sheet). Time to relax was given to patients while performing the setup of the EEG apparatus and participants were instructed to sit comfortably and focus only on the screen. External interference was minimized to avoid distractions that could result in inadvertent saccadic movements. Data was collected from 12 subjects with an average age of 25 years. Several popular methods were evaluated in order to find the most suitable for ocular artefact correction and 3 were selected for assessment: 1. Independent Components Analysis (ICA), 2. Wavelet Decomposition and 3. Wiener Filtering. The traces resulting from these methods were then analysed and compared. ICA is an algorithm that maximizes the independence of different components of a signal by finding a linear coordinate system that creates signals that are statistically independent [ 16 ]. ICA is used for Blind Source Separation. As ocular artefacts do not correspond to neural activity (i.e. they have a different source), ICA seemed a suitable approach to ocular artefact correction in EEG signals. The ICA algorithm used is present in the EEGLAB toolbox for Matlab and uses the  infomax  learning rule [ 1 ]. This rule minimizes the mutual information in the components in the output, thus maximizing their statistical independence. The original  infomax  condition fails to separate sub-Gaussian sources due to the sigmoid function used; a solution to this problem was proposed by Bell and Sejnowski and consisted of a flexible sigmoid function [ 1 ], but empirical results have shown that sometimes it is not possible to find independent components with this approach, alongside it being highly demanding in terms of computational load. To evaluate the Gaussianity of a distribution, a measure of its kurtosis can be used. Kurtosis is defined as the 4th order cumulant and gives a measure of the shape of a distribution. A cumulant is used to describe and in some cases approximate a normal distribution; these are similar to moments in the sense that two distributions with identical moments will also have identical cumulants. To overcome the problems of the original rule proposed by Bell and Sejnowski, an extended version of their algorithm was created: in this version the algorithm switches according to the kurtosis of the distribution of the data points. This means that according to the sign of the kurtosis, the learning rule is updated and this way it is possible to overcome the original problem. Simulations run on datasets with multiple sources and a variety of sub- and super-Gaussian distributions show that this extended version of the  infomax  algorithm is able to separate the sources [ 17 ]. After the computation of this filter function and in order to apply it to the whole signal, either the filter function has to be inversely transformed to be in a time basis or the signal has to be transformed to be in Fourier space. The signal is then convolved (time) or multiplied (Fourier) with the filter and the noise should be removed. Wavelets and wavelet decomposition are tools used in signal processing to analyse, correct and characterize signals. Wavelet functions define the basis over which the signal is going to be decomposed. From the several different types of wavelets in existence in signal processing it is possible to choose some whose properties adjust better to a specific purpose or case. In the case of artefact correction, wavelets that mimic the artefact will be more suitable, since the coefficients of the transform will be higher in the artefact zones. The main issue of the Discrete Wavelet Transform (DWT) is that it is not time-invariant, and thus the translation invariance property is lost, i.e. the translated DWT of a signal is not the same as the DWT of a translated signal. Stationary Wavelet transform is a variation of the usual Discrete Wavelet transform. The advantage relies on the independence of the choice of origin for the wavelets, which is achieved by applying appropriate high and low pass filters to the data at each level, thus producing two sequences at the next level. This way there is no decimation, instead the filters are changing at each level by zero-padding in a well-defined way. The details of the filter adaptation are described in [ 19 ]. The Stationary Wavelet Transform (SWT) contains the coefficients of the Discrete Wavelet Transform but shifted according to the choice of the origin of DWT. There is no restriction on the localisation as the stationary wavelet transform fills the gaps between coefficients in decimated DWT [ 19 ]. In the case of artefact correction of the EEG, [ 12 ] show a simple way to correct the eye blink artefacts from the EEG using Stationary Wavelet Transforms and Symlet Wavelets (part of the Daubechies [ 20 ] family) of level 3. In this paper they show a method to correct the artefacts with a simple threshold of the wavelet coefficients. EEG recording. Different colours represent different channels; the  spikes  in the signal are blink artefacts Average Blink for one subject. The artefact extracted is quite large and thus can influence the use of the data Top  EEG signal before artefact correction.  Bottom  Same signal after correction of artefacts with ICA. The artefacts that correspond to the  spikes  in the  upper plot  are reduced in the  bottom plot . The  black window  represents the region that was zoomed for the detail plot in Fig.  5 Detail plot of two blink artefacts.  Top  before correction;  Bottom  after correction with ICA EEG signal before and after correction of artefacts with Wiener filter.  Top  signal before artefact correction;  Bottom  signal after artefact correction. The black window represents the region of the signal that is zoomed in the detail plot (Fig.  7 ) Detail plot of the EEG signal.  Top  signal before artefact correction;  Bottom  signal after artefact correction with Wiener filter EEG signal before and after correction of artefacts with Wavelet Decomposition.  Top  signal before artefact correction;  Bottom  signal after artefact correction. The  black window  indicates the region of the signal that is zoomed in the detail plot (Fig.  9 ) Detail plot of the EEG signal.  Top  signal before artefact correction;  Bottom  signal after artefact correction with Wavelet Decomposition EEG signal before and after correction of artefacts with Blind ICA.  Top  signal before artefact correction;  Bottom  signal after artefact correction. The  black window  indicates the region of the signal that is zoomed in the detail plot (Fig.  9 ) Detail plot of the EEG signal.  Top  signal before artefact correction;  Bottom  signal after artefact correction with Blind ICA We studied the benefits of using an Eye-Tracker for the ultimate purpose of real-time, on-line Ocular Artefact correction of EEG data. To this end, we implemented standardised signal processing methods such as ICA or Wavelet Decomposition, as well as a Wiener Filter—a method not generally used in conventional “blind” EEG artefact correction. Eye-tracking provides automatic annotation of eye-movement artefact events. The approach here is pragmatic, we use the event annotation to perform targeted “blind” artefact removal: i.e. we make here as much as possible use of existing EEG processing pipelines, but guide their processing only to event-tagged periods of the data. Our results show that all 3 methods are successful in correcting eye movement artefacts, although Event-Driven ICA seems to yield the best signal after correction. This is expected, considering that the origins of the artefact and the signal are different, and thus minimising mutual information between potential sources is going to have significant benefits. When compared to the other methods, Blind ICA clearly is stricter with the data and sometimes leads to an over-correction. In Fig.  11  we can clearly see that the data, although it might preserve most of its frequency spectrum, has been severely affected by the corrective measure. As expected from EEG data, there is high inter- and intra-subject variability on the EEG recordings; shape of head, changes in electrode impedance or subject behaviour can influence the data recordings, by introducing artefacts and non-linear trends in the signal. Moreover, attention or drowsiness can influence the Eye-Tracking data quality over longer usage times [ 24 ]. The Wiener Filter is the method that is most prone to failure, as it relies on an effective extraction of the average artefact. Moreover it will filter out all the frequencies represented in the artefact, which are low (duration of about 200 ms) [ 25 ] and thus can eliminate relevant information from the EEG signal [ 26 ,  3 ,  27 ]. One improvement that could be performed to the Wavelet Decomposition method is the use of a more complex adaptive thresholding technique, since the one used for this analysis combines only the mean and variance of the signal to obtain a threshold; other methods have been tested in “blind” approaches [ 28 ,  29 ] and thus could be implemented in this study. The ICA technique could be implemented as an online correction technique, though it would lead to some delay in the output of results. Wavelet and Wiener filter methods can only be used for post-processing and not for online correction with the approaches described in this work. As further work we would like to appoint the validation of these techniques and their pertinence in artefact correction. A validation approach was attempted, with a Movement Imagery task and a simple K-Nearest Neighbours classifier. The goal was to examine the classifier’s accuracy for different methods of ocular artefact correction, but in the experiments the number of ocular artefacts was correlated with the Movement Imagery epochs (number of blinks increased in Movement Imagery and lowered in Rest epochs), thus proving this validation method as unable to accurately find the best corrective algorithm. Online implementation is although required for this purpose, but the usage of an eye tracker that is not affected by external electromagnetic fields (unlike, for example, electrooculograms or magnetic search coils [ 30 ]). Our work suggests simple steps towards a cleaner EEG signal, hopefully with more usable neural information being conveyed in it and useable in real-time. The potential benefits of a clean EEG signal that can be expected are among a better understanding of neural signals and better use for these, such as in Brain Machine Interfaces that can be used to help patients suffering from Locked in Syndrome, as an example. The supervised clean-up of EEG data supports current developments in data-efficient EEG decoding algorithms [ 31 ] and by reducing spurious variability in a predictable way, the rapid automatic tuning of EEG-based systems in clinical settings where patient time is precious [ 32 ,  33 ]. Integration of EEG and eye tracking for artefact correction is going to become a natural by-product of BCI approaches for assistive devices, such as mind-controlled wheel-chairs [ 34 ], becoming multi-modal [ 35 ]. Thus, eye-tracking based EEG artefact removal is an  en passant  benefit that should be seized in the future. We acknowledge NEUROTECHNIX 2014 (Rome, Italy), where this work was originally contributed for their conference proceedings [ 36 ], and we are grateful that the paper was now selected for this publication format. Advertisement Over 10 million scientific documents at your fingertips  2019 Springer Nature Switzerland AG. Part of  Springer Nature . Not logged in Google [Search Crawler] (3000811494) 66.249.69.166 Your Privacy Strictly Necessary Cookies Performance Cookies Functional Cookies Targeting Cookies More Information Active Always Active We use cookies to personalise content and ads, to provide social media features and to analyse our traffic. We also share information about your use of our site with our social media, advertising and analytics partners in accordance with our  Privacy Statement . You can manage your preferences in Manage Cookies. 