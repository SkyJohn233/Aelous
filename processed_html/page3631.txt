GitHub - baggepinnen/LowLevelParticleFilters.jl: Simple particle/kalman filtering, smoothing and parameter estimation GitHub is home to over 40 million developers working together to host and review code, manage projects, and build software together.               Use Git or checkout with SVN using the web URL.                           Want to be notified of new releases in               baggepinnen/LowLevelParticleFilters.jl ?             If nothing happens,  download GitHub Desktop  and try again. Go back If nothing happens,  download GitHub Desktop  and try again. Go back If nothing happens,  download Xcode  and try again. Go back If nothing happens,  download the GitHub extension for Visual Studio  and try again. Go back This readme is auto generated from the file  src/example_lineargaussian.jl  using  Literate.jl We provide a number of filter types This example demostrates how we set up the filters, both PF and KF, for a simple linear system. Defining a particle filter is straightforward, one must define the distribution of the noise  df  in the dynamics function,  dynamics(x,u)  and the noise distribution  dg  in the measurement function  measurement(x) . The distribution of the initial state  d0  must also be provided. An example for a linear Gaussian system is given below. Define problem Define random linear state-space system The following two functions are required by the filter We are now ready to define and use a filter If you want to perform filtering using vectors of inputs and measurements, try any of the functions To see how the performance varies with the number of particles, we simulate several times. The following code simulates the system and performs filtering using the simulated measuerments. We do this for varying number of time steps and varying number of particles. Propagated 8400000 particles in 3.568745383 seconds for an average of 2353.7683691344473 particles per millisecond We then plot the results We also provide a particle smoother, based on forward filtering, backward simulation (FFBS) We can plot the particles themselves as well A Kalman filter is easily created using the constructor. Many of the functions defined for particle filters, are defined also for Kalman filters, e.g.: It can also be called in a loop like the  pf  above Tuning a particle filter can be quite the challenge. To assist with this, we provide som visualization tools The plot displays all states and all measurements. The heatmap in the background represents the weighted particle distributions per time step. For the measurement sequences, the heatmap represent the distibutions of predicted measurements. The blue dots corresponds to measured values. In this case, we simulated the data and we had access to states as well, if we do not have that, just omit  xreal .You can also manually step through the time-series using We provide som basic functionality for maximum likelihood estimation and MAP estimation Plot likelihood as function of the variance of the dynamics noise We can do the same with a Kalman filter as we can see, the result is quite noisy due to the stochastic nature of particle filtering. Plot and compare PF and KF To solve a MAP estimation problem, we need to define a function that takes a parameter vector and returns a particle filter The call to  exp  on the parameters is so that we can define log-normal priors Now we call the function  log_likelihood_fun  that returns a function to be minimized Since this is a low-dimensional problem, we can plot the LL on a 2d-grid Something seems to be off with this figure as the hottest spot is not really where we would expect it Optimization of the log likelihood can be done by, e.g., global/black box methods, see  BlackBoxOptim.jl . Standard tricks apply, such as performing the parameter search in log-space etc. This is pretty cool. We procede like we did for MAP above, but when calling the function  metropolis , we will get the entire posterior distribution of the parameter vector, for the small cost of a massive increase in computational cost. The call to  exp  on the parameters is so that we can define log-normal priors We also need to define a function that suggests a new point from the "proposal distribution". This can be pretty much anything, but it has to be symmetric since I was lazy and simplified an equation. If you are lucky, you can run the above threaded as well. I tried my best to make particle fitlers thread safe with their own rngs etc., but your milage may vary. The  AdvancedParticleFilter  type requires you to implement the same functions as the regular  ParticleFilter , but in this case you also need to handle sampling from the noise distributions yourself.The function  dynamics  must have a method signature like below. It must provide one method that accepts state vector, control vector, time and  noise::Bool  that indicates whether or not to add noise to the state. If noise should be added, this should be done inside  dynamics  An example is given below The  measurement_likelihood  function must have a method accepting state, measurement and time, and returning the log-likelihood of the measurement given the state, a simple example below: This gives you very high flexibility. The noise model in either function can, for instance, be a function of the state, something that is not possible for the simple  ParticleFilter To be able to simulate the  AdvancedParticleFilter  like we did with the simple filter above, the  measurement  method with the signature  measurement(x,t,noise=false)  must be available and return a sample measurement given state (and possibly time). For our example measurement model above, this would look like this We now create the  AdvancedParticleFilter  and use it in the same way as the other filters: We can even use this type as an AuxiliaryParticleFilter When  using LowLevelParticleFilters , a number of methods related to distributions are defined for static arrays, making  logpdf  etc. faster. We also provide a new kind of distribution:  TupleProduct  < : MultivariateDistribution  that behaves similarly to the  Product  distribution. The  TupleProduct  however stores the individual distributions in a tuple, has compile-time known length and supports  Mixed  < : ValueSupport , meaning that it can be a product of both  Continuous  and  Discrete  dimensions, somthing not supported by the standard  Product . Example A small benchmark @btime logpdf($d,$sv) # 22.651 ns (0 allocations: 0 bytes)@btime logpdf($dt,$sv) # 0.021 ns (0 allocations: 0 bytes)@btime logpdf($dm,$sv) # 0.021 ns (0 allocations: 0 bytes)Without loading  LowLevelParticleFilters , the timing for the native distributions are the following @btime logpdf($d,$sv) # 32.621 ns (1 allocation: 32 bytes) @btime logpdf($dm,$sv) # 46.415 ns (1 allocation: 96 bytes) This page was generated using  Literate.jl . 