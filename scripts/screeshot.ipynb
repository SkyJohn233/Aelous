{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "532 2330\n",
      "51 259\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open('data.pickle','rb') as f:\n",
    "    train,test = pickle.load(f)\n",
    "cnt = 0\n",
    "for x in train:\n",
    "    if x['is entity']=='1':\n",
    "        cnt+=1\n",
    "print(cnt,len(train))\n",
    "cnt = 0\n",
    "for x in test:\n",
    "    if x['is entity']=='1':\n",
    "        cnt+=1\n",
    "print(cnt,len(test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../webpage-classification/./render/render1344.png\n",
      "[[[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[242 242 242]\n",
      "  [242 242 242]\n",
      "  [242 242 242]\n",
      "  ...\n",
      "  [242 242 242]\n",
      "  [242 242 242]\n",
      "  [242 242 242]]\n",
      "\n",
      " [[242 242 242]\n",
      "  [242 242 242]\n",
      "  [242 242 242]\n",
      "  ...\n",
      "  [242 242 242]\n",
      "  [242 242 242]\n",
      "  [242 242 242]]\n",
      "\n",
      " [[242 242 242]\n",
      "  [242 242 242]\n",
      "  [242 242 242]\n",
      "  ...\n",
      "  [242 242 242]\n",
      "  [242 242 242]\n",
      "  [242 242 242]]]\n"
     ]
    }
   ],
   "source": [
    "print('../../webpage-classification/'+train[0]['render'])\n",
    "img = cv2.imread('../../webpage-classification/'+train[0]['render'])\n",
    "print(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "for x in train:\n",
    "    f = plt.imread('../../webpage-classification/'+x['render'])\n",
    "    if f.shape[0]>f.shape[1]:\n",
    "        f= f[0:f.shape[1],0:f.shape[1],:]\n",
    "        #print(x['url'],f.shape)\n",
    "    plt.imsave('./data/'+x['is entity']+'/'+x['render'],f)\n",
    "        #plt.imshow(f)\n",
    "        #plt.show()\n",
    "        #cv2.imshow(f)\n",
    "    #print(f.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No\n",
      "./render/render1344.png\n",
      "No\n",
      "./render/render644.png\n",
      "No\n",
      "./render/render209.png\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import tensorflow as tf\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "import IPython.display as display\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "import pathlib\n",
    "#data_dir = tf.keras.utils.get_file(origin='https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz',\n",
    "#                                         fname='flower_photos', untar=True)\n",
    "#data_dir = pathlib.Path(data_dir)\n",
    "\n",
    "#image_count = len(list(data_dir.glob('*/*.jpg')))\n",
    "\n",
    "#roses = list(data_dir.glob('roses/*'))\n",
    "\n",
    "for image in train:\n",
    "    #image_path = image['render']\n",
    "    tag = image['is entity']\n",
    "    if tag=='0':\n",
    "        tag = \"No\"\n",
    "    else:\n",
    "        tag = \"Yes\"\n",
    "    print(tag)\n",
    "    img = Image.open('../../webpage-classification/'+image_path)\n",
    "    print(image_path)\n",
    "    #Image.save()\n",
    "    #display.display(Image.open('../../webpage-classification/'+image_path['render']))\n",
    "    #display.display(Image.open(str(image_path)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The 1./255 is to convert from uint8 to float32 in range [0,1].\n",
    "image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "BATCH_SIZE = 32\n",
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224\n",
    "image_count = len(train)\n",
    "STEPS_PER_EPOCH = np.ceil(image_count/BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_gen = image_generator.flow_from_directory(directory=str(data_dir),\n",
    "                                                     batch_size=BATCH_SIZE,\n",
    "                                                     shuffle=True,\n",
    "                                                     target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "                                                     classes = list(CLASS_NAMES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow_hub>=0.6.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/00/0e/a91780d07592b1abf9c91344ce459472cc19db3b67fdf3a61dca6ebb2f5c/tensorflow_hub-0.7.0-py2.py3-none-any.whl (89kB)\n",
      "\u001b[K     |████████████████████████████████| 92kB 2.6MB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python3.5/dist-packages (from tensorflow_hub>=0.6.0) (3.10.0)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.5/site-packages (from tensorflow_hub>=0.6.0) (1.15.1)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.5/dist-packages (from tensorflow_hub>=0.6.0) (1.13.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.5/dist-packages (from protobuf>=3.4.0->tensorflow_hub>=0.6.0) (41.6.0)\n",
      "Requirement already satisfied: mkl-fft in /usr/local/lib/python3.5/dist-packages (from numpy>=1.12.0->tensorflow_hub>=0.6.0) (1.0.6)\n",
      "Requirement already satisfied: mkl-random in /usr/local/lib/python3.5/dist-packages (from numpy>=1.12.0->tensorflow_hub>=0.6.0) (1.0.1.1)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.5/dist-packages (from numpy>=1.12.0->tensorflow_hub>=0.6.0) (2019.0)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.5/dist-packages (from numpy>=1.12.0->tensorflow_hub>=0.6.0) (2019.0)\n",
      "Requirement already satisfied: icc-rt in /usr/local/lib/python3.5/dist-packages (from numpy>=1.12.0->tensorflow_hub>=0.6.0) (2019.0)\n",
      "Requirement already satisfied: intel-numpy in /usr/local/lib/python3.5/dist-packages (from mkl-fft->numpy>=1.12.0->tensorflow_hub>=0.6.0) (1.15.1)\n",
      "Requirement already satisfied: tbb==2019.* in /usr/local/lib/python3.5/dist-packages (from tbb4py->numpy>=1.12.0->tensorflow_hub>=0.6.0) (2019.0)\n",
      "Requirement already satisfied: intel-openmp in /usr/local/lib/python3.5/dist-packages (from mkl->numpy>=1.12.0->tensorflow_hub>=0.6.0) (2019.0)\n",
      "Installing collected packages: tensorflow-hub\n",
      "Successfully installed tensorflow-hub-0.7.0\n",
      "Collecting tensorflow>=2.0.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/49/cfb96f19d34f4bc3543a4bd0212cd146e38a5ad1ad4bbd653cfee8943bc1/tensorflow-2.1.0-cp35-cp35m-manylinux2010_x86_64.whl (421.8MB)\n",
      "\u001b[K     |████████████████████████████████| 421.8MB 41kB/s s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/lib/python3/dist-packages (from tensorflow>=2.0.0) (0.29.0)\n",
      "Collecting tensorflow-estimator<2.2.0,>=2.1.0rc0\n",
      "  Using cached https://files.pythonhosted.org/packages/18/90/b77c328a1304437ab1310b463e533fa7689f4bfc41549593056d812fab8e/tensorflow_estimator-2.1.0-py2.py3-none-any.whl\n",
      "Collecting keras-preprocessing>=1.1.0\n",
      "  Using cached https://files.pythonhosted.org/packages/28/6a/8c1f62c37212d9fc441a7e26736df51ce6f0e38455816445471f10da4f0a/Keras_Preprocessing-1.1.0-py2.py3-none-any.whl\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Using cached https://files.pythonhosted.org/packages/b8/83/755bd5324777875e9dff19c2e59daec837d0378c09196634524a3d7269ac/opt_einsum-3.1.0.tar.gz\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.5/dist-packages (from tensorflow>=2.0.0) (1.13.0)\n",
      "Collecting google-pasta>=0.1.6\n",
      "  Using cached https://files.pythonhosted.org/packages/c3/fd/1e86bc4837cc9a3a5faf3db9b1854aa04ad35b5f381f9648fbe81a6f94e4/google_pasta-0.1.8-py3-none-any.whl\n",
      "Collecting keras-applications>=1.0.8\n",
      "  Using cached https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl\n",
      "Collecting tensorboard<2.2.0,>=2.1.0\n",
      "  Using cached https://files.pythonhosted.org/packages/40/23/53ffe290341cd0855d595b0a2e7485932f473798af173bbe3a584b99bb06/tensorboard-2.1.0-py3-none-any.whl\n",
      "Collecting scipy==1.4.1; python_version >= \"3\"\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c1/60/8cbf00c0deb50a971e6e3a015fb32513960a92867df979870a454481817c/scipy-1.4.1-cp35-cp35m-manylinux1_x86_64.whl (26.0MB)\n",
      "\u001b[K     |████████████████████████████████| 26.0MB 62.5MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.5/dist-packages (from tensorflow>=2.0.0) (1.11.2)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.5/dist-packages (from tensorflow>=2.0.0) (3.10.0)\n",
      "Collecting gast==0.2.2\n",
      "  Using cached https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
      "Collecting numpy<2.0,>=1.16.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/52/e6/1715e592ef47f28f3f50065322423bb75619ed2f7c24be86380ecc93503c/numpy-1.18.1-cp35-cp35m-manylinux1_x86_64.whl (19.9MB)\n",
      "\u001b[K     |████████████████████████████████| 20.0MB 57.5MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting astor>=0.6.0\n",
      "  Using cached https://files.pythonhosted.org/packages/c3/88/97eef84f48fa04fbd6750e62dcceafba6c63c81b7ac1420856c8dcc0a3f9/astor-0.8.1-py2.py3-none-any.whl\n",
      "Collecting absl-py>=0.7.0\n",
      "  Using cached https://files.pythonhosted.org/packages/1a/53/9243c600e047bd4c3df9e69cfabc1e8004a82cac2e0c484580a78a94ba2a/absl-py-0.9.0.tar.gz\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.5/dist-packages (from tensorflow>=2.0.0) (1.25.0)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Using cached https://files.pythonhosted.org/packages/8a/48/a76be51647d0eb9f10e2a4511bf3ffb8cc1e6b14e9e4fab46173aa79f981/termcolor-1.1.0.tar.gz\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.5/dist-packages (from keras-applications>=1.0.8->tensorflow>=2.0.0) (2.10.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.5/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow>=2.0.0) (2.22.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.5/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow>=2.0.0) (1.7.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.5/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow>=2.0.0) (3.1.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.5/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow>=2.0.0) (41.6.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.5/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow>=2.0.0) (0.4.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.5/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow>=2.0.0) (0.16.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.5/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow>=2.0.0) (1.24.2)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.5/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow>=2.0.0) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.5/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow>=2.0.0) (2019.9.11)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.5/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow>=2.0.0) (3.0.4)\n",
      "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.5/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow>=2.0.0) (4.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.5/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow>=2.0.0) (0.2.7)\n",
      "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.5/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow>=2.0.0) (3.1.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.5/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow>=2.0.0) (1.3.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.5/dist-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow>=2.0.0) (0.4.7)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.5/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow>=2.0.0) (3.1.0)\n",
      "Building wheels for collected packages: opt-einsum, gast, absl-py, termcolor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Building wheel for opt-einsum (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for opt-einsum: filename=opt_einsum-3.1.0-cp35-none-any.whl size=63904 sha256=2a939d1ef410d9c4ab8c29ef98b2131269ec3e018cad7734248486ddc2ec37f4\n",
      "  Stored in directory: /root/.cache/pip/wheels/2c/b1/94/43d03e130b929aae7ba3f8d15cbd7bc0d1cb5bb38a5c721833\n",
      "  Building wheel for gast (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for gast: filename=gast-0.2.2-cp35-none-any.whl size=7636 sha256=e6b4de4a6197202d3d0048c82f3e00b28f4609e396c892c2e1b11417829e4aff\n",
      "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
      "  Building wheel for absl-py (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for absl-py: filename=absl_py-0.9.0-cp35-none-any.whl size=119399 sha256=18eb18bcaa1d39aa8f6efeb5c1556a7ab94838cd83797d19ff151e607687dd18\n",
      "  Stored in directory: /root/.cache/pip/wheels/8e/28/49/fad4e7f0b9a1227708cbbee4487ac8558a7334849cb81c813d\n",
      "  Building wheel for termcolor (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for termcolor: filename=termcolor-1.1.0-cp35-none-any.whl size=5680 sha256=795c6087f4e230fd897020b2ecb7c087d75ac9a5e50d0d666d447cc124f8f41d\n",
      "  Stored in directory: /root/.cache/pip/wheels/7c/06/54/bc84598ba1daf8f970247f550b175aaaee85f68b4b0c5ab2c6\n",
      "Successfully built opt-einsum gast absl-py termcolor\n",
      "\u001b[31mERROR: scikit-image 0.15.0 requires pillow>=4.3.0, which is not installed.\u001b[0m\n",
      "\u001b[31mERROR: imageio 2.6.1 requires pillow, which is not installed.\u001b[0m\n",
      "Installing collected packages: tensorflow-estimator, numpy, keras-preprocessing, opt-einsum, google-pasta, keras-applications, absl-py, tensorboard, scipy, gast, astor, termcolor, tensorflow\n",
      "  Found existing installation: numpy 1.15.1\n",
      "    Uninstalling numpy-1.15.1:\n",
      "      Successfully uninstalled numpy-1.15.1\n",
      "  Found existing installation: scipy 1.1.0\n",
      "    Uninstalling scipy-1.1.0:\n",
      "      Successfully uninstalled scipy-1.1.0\n",
      "Successfully installed absl-py-0.9.0 astor-0.8.1 gast-0.2.2 google-pasta-0.1.8 keras-applications-1.0.8 keras-preprocessing-1.1.0 numpy-1.18.1 opt-einsum-3.1.0 scipy-1.4.1 tensorboard-2.1.0 tensorflow-2.1.0 tensorflow-estimator-2.1.0 termcolor-1.1.0\n",
      "(3, 128)\n"
     ]
    }
   ],
   "source": [
    "!pip install \"tensorflow_hub>=0.6.0\"\n",
    "!pip install \"tensorflow>=2.0.0\"\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "module_url = \"https://tfhub.dev/google/nnlm-en-dim128/2\"\n",
    "embed = hub.KerasLayer(module_url)\n",
    "embeddings = embed([\"A long sentence.\", \"single-word\",\n",
    "                  \"http://example.com\"])\n",
    "print(embeddings.shape)  #(3,128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor_url = \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/2\" #@param {type:\"string\"}\n",
    "\n",
    "feature_extractor_layer = hub.KerasLayer(feature_extractor_url,\n",
    "                                         input_shape=(224,224,3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
